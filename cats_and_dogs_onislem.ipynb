{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Resizing, Rescaling\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from the zip file\n",
    "local_zip = 'data/kagglecatsanddogs_5340.zip'\n",
    "\n",
    "with ZipFile(local_zip, 'r') as zip:\n",
    "    zip.extractall(\"data/\")\n",
    "os.remove(\"data/CDLA-Permissive-2.0.pdf\")\n",
    "os.remove(\"data/readme[1].txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/PetImages/Cat/')))\n",
    "print(len(os.listdir('data/PetImages/Dog/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data/resized_images created\n"
     ]
    }
   ],
   "source": [
    "# create folders for the resized images\n",
    "create_folder_names = [\"data/resized_images\"]\n",
    "\n",
    "for dir in create_folder_names:\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "        print(\"Directory \" + dir + \" created\")\n",
    "    except:\n",
    "        print(\"Directory \" + dir + \" not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/PetImages/Cat/666.jpg is empty\n",
      "data/PetImages/Cat/Thumbs.db is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12499/12499 [02:12<00:00, 94.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499 images resized\n",
      "data/PetImages/Dog/11702.jpg is empty\n",
      "data/PetImages/Dog/Thumbs.db is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 11429/12499 [02:20<00:13, 77.45it/s] c:\\Users\\Undergrad\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 12499/12499 [02:33<00:00, 81.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499 images resized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# resize the images and save them in the resized_images folder\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "def resize_image(source, destination, width, height):\n",
    "    all_files = []\n",
    "    type = source.split(\"/\")[-1]\n",
    "    \n",
    "    for file in os.listdir(source):\n",
    "        file_path = source + \"/\" + file\n",
    "    \n",
    "        if os.path.getsize(file_path) and file.endswith(\".jpg\"):\n",
    "            all_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"{file_path} is empty\")\n",
    "        \n",
    "    for file in tqdm(all_files):       \n",
    "        img = load_img(file, target_size=(width, height))\n",
    "        img = img_to_array(img)\n",
    "        img = array_to_img(img)\n",
    "        img.save(destination + \"/\" + type.lower() + \"_\" + file.split(\"/\")[-1])\n",
    "        \n",
    "    print(f\"{len(all_files)} images resized\")\n",
    "        \n",
    "\n",
    "resize_image(\"data/PetImages/Cat\", \"data/resized_images/\", 150, 150)\n",
    "resize_image(\"data/PetImages/Dog\", \"data/resized_images/\", 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data/pets_images created\n",
      "Directory data/pets_images/train created\n",
      "Directory data/pets_images/test created\n",
      "Directory data/pets_images/validation created\n"
     ]
    }
   ],
   "source": [
    "# create folders for the train, validation and test sets\n",
    "create_folder_names = [\n",
    "    \"data/pets_images\",\n",
    "    \"data/pets_images/train\",\n",
    "    \"data/pets_images/test\",\n",
    "    \"data/pets_images/validation\",\n",
    "]\n",
    "\n",
    "for dir in create_folder_names:\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "        print(\"Directory \" + dir + \" created\")\n",
    "    except:\n",
    "        print(\"Directory \" + dir + \" not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17498/17498 [02:00<00:00, 145.53it/s]\n",
      "100%|██████████| 3749/3749 [00:27<00:00, 135.62it/s]\n",
      "100%|██████████| 3751/3751 [00:27<00:00, 137.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# split the data into train, validation and test sets\n",
    "def split_data(source, train_dir, test_dir, val_dir, train_size, test_size):\n",
    "    all_filess = []\n",
    "    \n",
    "    for file in os.listdir(source):\n",
    "        file_path = source + \"/\" + file\n",
    "        \n",
    "        if os.path.getsize(file_path):\n",
    "            all_filess.append(file_path)\n",
    "        else:\n",
    "            print(f\"{file_path} is empty\")\n",
    "    \n",
    "    n_files = len(all_filess)\n",
    "    split_point = int(n_files * train_size)\n",
    "    \n",
    "    shuffled = random.sample(all_filess, n_files)\n",
    "    train_set = shuffled[:split_point]\n",
    "    others = shuffled[split_point:]\n",
    "    \n",
    "    n_files = len(others)\n",
    "    split_point = int(n_files * (test_size / (1 - train_size)))\n",
    "    \n",
    "    test_set = others[:split_point]\n",
    "    val_set = others[split_point:]\n",
    "    \n",
    "    for file in tqdm(train_set):\n",
    "        copyfile(file, train_dir + \"/\" + file.split(\"/\")[-1])\n",
    "    \n",
    "    for file in tqdm(test_set):\n",
    "        copyfile(file, test_dir + \"/\" + file.split(\"/\")[-1])\n",
    "        \n",
    "    for file in tqdm(val_set):\n",
    "        copyfile(file, val_dir + \"/\" + file.split(\"/\")[-1])\n",
    "        \n",
    "src_dir = \"data/resized_images/\"\n",
    "train_dir = \"data/pets_images/train/\"\n",
    "test_dir = \"data/pets_images/test/\"\n",
    "val_dir = \"data/pets_images/validation/\"\n",
    "\n",
    "train_size = 0.7\n",
    "test_size = 0.15\n",
    "\n",
    "split_data(src_dir, train_dir, test_dir, val_dir, train_size, test_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8c179a8effd330e81a694212de9776c189edb37372fff9a89e9c3c0a5716602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
