{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 18:26:14.202783: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-26 18:26:16.692351: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-26 18:26:16.695302: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-26 18:26:17.105254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 18:26:17.105502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-08-26 18:26:17.105540: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-26 18:26:17.109061: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-26 18:26:17.109162: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-26 18:26:17.110967: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-26 18:26:17.111385: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-26 18:26:17.115333: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-08-26 18:26:17.116249: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-26 18:26:17.116449: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-26 18:26:17.116598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 18:26:17.116884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 18:26:17.117082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-08-26 18:26:17.117166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 18:26:17.759853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-26 18:26:17.759904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-08-26 18:26:17.759915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-08-26 18:26:17.760189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 18:26:17.760517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 18:26:17.760845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 18:26:17.761093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Resizing, Rescaling\n",
    "from shutil import copyfile\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from the zip file\n",
    "local_zip = 'data/kagglecatsanddogs_5340.zip'\n",
    "\n",
    "with ZipFile(local_zip, 'r') as zip:\n",
    "    zip.extractall(\"data/\")\n",
    "os.remove(\"data/CDLA-Permissive-2.0.pdf\")\n",
    "os.remove(\"data/readme[1].txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/PetImages/Cat/')))\n",
    "print(len(os.listdir('data/PetImages/Dog/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data/resized_images created\n"
     ]
    }
   ],
   "source": [
    "# create folders for the resized images\n",
    "create_folder_names = [\"data/resized_images\"]\n",
    "\n",
    "for dir in create_folder_names:\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "        print(\"Directory \" + dir + \" created\")\n",
    "    except:\n",
    "        print(\"Directory \" + dir + \" not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/PetImages/Cat/Thumbs.db is empty\n",
      "data/PetImages/Cat/666.jpg is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12499/12499 [00:28<00:00, 437.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499 images resized\n",
      "data/PetImages/Dog/Thumbs.db is empty\n",
      "data/PetImages/Dog/11702.jpg is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 7426/12499 [00:16<00:11, 442.86it/s]/home/yasin.142.tarakci/miniconda3/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:845: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 12499/12499 [00:27<00:00, 452.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499 images resized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# resize the images and save them in the resized_images folder\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "def resize_image(source, destination, width, height):\n",
    "    all_files = []\n",
    "    type = source.split(\"/\")[-1]\n",
    "    \n",
    "    for file in os.listdir(source):\n",
    "        file_path = source + \"/\" + file\n",
    "    \n",
    "        if os.path.getsize(file_path) and file.endswith(\".jpg\"):\n",
    "            all_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"{file_path} is empty\")\n",
    "        \n",
    "    for file in tqdm(all_files):       \n",
    "        img = load_img(file, target_size=(width, height))\n",
    "        img = img_to_array(img)\n",
    "        img = array_to_img(img)\n",
    "        img.save(destination + \"/\" + type.lower() + \"_\" + file.split(\"/\")[-1])\n",
    "        \n",
    "    print(f\"{len(all_files)} images resized\")\n",
    "        \n",
    "\n",
    "resize_image(\"data/PetImages/Cat\", \"data/resized_images/\", 150, 150)\n",
    "resize_image(\"data/PetImages/Dog\", \"data/resized_images/\", 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data/pets_images created\n",
      "Directory data/pets_images/train created\n",
      "Directory data/pets_images/test created\n",
      "Directory data/pets_images/validation created\n"
     ]
    }
   ],
   "source": [
    "# create folders for the train, validation and test sets\n",
    "create_folder_names = [\n",
    "    \"data/pets_images\",\n",
    "    \"data/pets_images/train\",\n",
    "    \"data/pets_images/test\",\n",
    "    \"data/pets_images/validation\",\n",
    "]\n",
    "\n",
    "for dir in create_folder_names:\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "        print(\"Directory \" + dir + \" created\")\n",
    "    except:\n",
    "        print(\"Directory \" + dir + \" not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17498/17498 [00:01<00:00, 9243.44it/s]\n",
      "100%|██████████| 3749/3749 [00:00<00:00, 9811.76it/s] \n",
      "100%|██████████| 3751/3751 [00:00<00:00, 9816.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# split the data into train, validation and test sets\n",
    "def split_data(source, train_dir, test_dir, val_dir, train_size, test_size):\n",
    "    all_filess = []\n",
    "    \n",
    "    for file in os.listdir(source):\n",
    "        file_path = source + \"/\" + file\n",
    "        \n",
    "        if os.path.getsize(file_path):\n",
    "            all_filess.append(file_path)\n",
    "        else:\n",
    "            print(f\"{file_path} is empty\")\n",
    "    \n",
    "    n_files = len(all_filess)\n",
    "    split_point = int(n_files * train_size)\n",
    "    \n",
    "    shuffled = random.sample(all_filess, n_files)\n",
    "    train_set = shuffled[:split_point]\n",
    "    others = shuffled[split_point:]\n",
    "    \n",
    "    n_files = len(others)\n",
    "    split_point = int(n_files * (test_size / (1 - train_size)))\n",
    "    \n",
    "    test_set = others[:split_point]\n",
    "    val_set = others[split_point:]\n",
    "    \n",
    "    for file in tqdm(train_set):\n",
    "        copyfile(file, train_dir + \"/\" + file.split(\"/\")[-1])\n",
    "    \n",
    "    for file in tqdm(test_set):\n",
    "        copyfile(file, test_dir + \"/\" + file.split(\"/\")[-1])\n",
    "        \n",
    "    for file in tqdm(val_set):\n",
    "        copyfile(file, val_dir + \"/\" + file.split(\"/\")[-1])\n",
    "        \n",
    "src_dir = \"data/resized_images/\"\n",
    "train_dir = \"data/pets_images/train/\"\n",
    "test_dir = \"data/pets_images/test/\"\n",
    "val_dir = \"data/pets_images/validation/\"\n",
    "\n",
    "train_size = 0.7\n",
    "test_size = 0.15\n",
    "\n",
    "split_data(src_dir, train_dir, test_dir, val_dir, train_size, test_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5e2d9ad942c1d3d683155d372f08253bcbceeb98ef25b4d05e6d0c31073834"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
